{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import pycolmap\n",
    "from deep_image_matching.thirdparty.transformations import (\n",
    "    affine_matrix_from_points,\n",
    "    decompose_matrix,\n",
    ")\n",
    "from deep_image_matching.triangulation import db_from_existing_poses\n",
    "from deep_image_matching.utils import COLMAPDatabase, OutputCapture\n",
    "\n",
    "root_path = Path(\"datasets/belv_20230725\")\n",
    "image_dir = root_path / \"images\"\n",
    "\n",
    "sfm_dir = root_path / \"results_superpoint+lightglue_bruteforce_quality_highest\"\n",
    "sfm_rec_path = sfm_dir / \"reconstruction\"\n",
    "\n",
    "# Output path for the triangulated markers\n",
    "output_path = root_path / \"marker_triang\"\n",
    "db_path = output_path / \"database_markers.db\"\n",
    "\n",
    "# Image coordinates of the markers\n",
    "markers_file = root_path / \"markers_image_20230725.csv\"\n",
    "\n",
    "# World coordinates of the markers\n",
    "georef_points = root_path / \"markers_utm.csv\"\n",
    "\n",
    "output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Get image list\n",
    "images = sorted(image_dir.glob(\"*\"))\n",
    "\n",
    "# Define a subset of the markers to use (leve none to use all)\n",
    "# markers_to_use = [\"D38\", \"T2\", \"F2\", \"F4\", \"F10\", \"F20\"]\n",
    "markers_to_use = [\"D38\", \"F2\", \"F4\", \"F10\", \"F20\"]\n",
    "\n",
    "\n",
    "# Dense reconstruction path to georeference\n",
    "dense_rec_path = root_path / \"results_roma_bruteforce_quality_high/dense_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read marker image coordinates and create keypoints dictionary with the form:\n",
    "# {\"image_name\": keypoints_array}\n",
    "# {\n",
    "#     \"image1.jpg\": np.array([[x1, y1], [x2, y2], ...]),\n",
    "#     \"image2.jpg\": np.array([[x1, y1], [x2, y2], ...]),\n",
    "#     ...\n",
    "# }\n",
    "markers_image = pd.read_csv(markers_file, header=None, names=[\"image\", \"marker\", \"x\", \"y\"])\n",
    "markers_image.sort_values([\"image\", \"marker\"], inplace=True, ascending=True)\n",
    "if markers_to_use:\n",
    "    markers_image = markers_image[markers_image[\"marker\"].isin(markers_to_use)]\n",
    "\n",
    "kpts = {}\n",
    "for image, gr in markers_image.groupby(\"image\"):\n",
    "    image = image + \".JPG\"\n",
    "    kpts[image] = gr[[\"x\", \"y\"]].values\n",
    "for k, v in kpts.items():\n",
    "    print(k, \":\\n\", v)\n",
    "\n",
    "# Manually create 1-to-1 matches array\n",
    "ids = np.arange(0, len(kpts[images[0].name]))\n",
    "matches_idx = np.array([ids, ids]).astype(np.int64).T\n",
    "print(\"matches idx:\\n\", matches_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot image with markers\n",
    "# import cv2\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# image_id = 1\n",
    "\n",
    "# img = cv2.cvtColor(cv2.imread(str(images[image_id])), cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img)\n",
    "# plt.scatter(\n",
    "#     kpts[images[image_id].name][:, 0],\n",
    "#     kpts[images[image_id].name][:, 1],\n",
    "#     c=\"r\",\n",
    "#     s=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features to h5 file\n",
    "features_h5 = output_path / \"features.h5\"\n",
    "with h5py.File(features_h5, \"w\") as f:\n",
    "    for image in images:\n",
    "        image_name = image.name\n",
    "        kp = kpts[image_name]\n",
    "        f.create_group(image_name)\n",
    "        f[image_name].create_dataset(\"keypoints\", data=kp, dtype=np.float32)\n",
    "\n",
    "# Save matches to h5 file\n",
    "matches_h5 = output_path / \"matches.h5\"\n",
    "with h5py.File(matches_h5, \"w\") as f:\n",
    "    image0, image1 = images[0].name, images[1].name\n",
    "    gr0 = f.create_group(image0)\n",
    "    gr0.create_dataset(image1, data=matches_idx, dtype=np.int64)\n",
    "\n",
    "pair_file = sfm_dir / \"pairs.txt\"\n",
    "\n",
    "# # print features_h5 content\n",
    "# with h5py.File(features_h5, \"r\") as f:\n",
    "#     print(f.keys())\n",
    "#     print(f[images[0].name].keys())\n",
    "#     print(f[images[0].name][\"keypoints\"][:])\n",
    "#     print(f[images[1].name].keys())\n",
    "#     print(f[images[1].name][\"keypoints\"][:])\n",
    "\n",
    "# # Print matches.h5 content\n",
    "# with h5py.File(matches_h5, \"r\") as f:\n",
    "#     print(f.keys())\n",
    "#     g0 = f[images[0].name]\n",
    "#     print(g0.keys())\n",
    "#     g1 = g0[images[1].name]\n",
    "#     print(g1.__array__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_rec = pycolmap.Reconstruction(sfm_rec_path)\n",
    "\n",
    "# Create a new database with the dense features and the known camera poses\n",
    "\n",
    "db_from_existing_poses(\n",
    "    db_path,\n",
    "    features_h5,\n",
    "    matches_h5,\n",
    "    sfm_rec_path,\n",
    "    pair_file,\n",
    "    do_geometric_verification=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the options for the triangulation according to the IncrementalPipelineOptions available in pycolmap\n",
    "# print(pycolmap.IncrementalPipelineOptions().summary())\n",
    "opt = dict(\n",
    "    min_num_matches=3,\n",
    "    triangulation=dict(\n",
    "        ignore_two_view_tracks=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the triangulation with the known camera poses\n",
    "verbose = True\n",
    "with OutputCapture(verbose):\n",
    "    with pycolmap.ostream():\n",
    "        reconstruction = pycolmap.triangulate_points(\n",
    "            sfm_rec,\n",
    "            db_path,\n",
    "            image_dir,\n",
    "            output_path,\n",
    "            options=opt,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = reconstruction.points3D\n",
    "for i, pt in sorted(pts.items()):\n",
    "    print(i, pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = reconstruction.images[1]\n",
    "img.points2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 1\n",
    "local = []\n",
    "for pt in reconstruction.images[image_id].points2D:\n",
    "    if not isinstance(pt.point3D_id, int) or pt.point3D_id < 0:\n",
    "        print(f\"Point {pt.point2D_idx} is not triangulated\")\n",
    "        continue\n",
    "    local.append(reconstruction.points3D[pt.point3D_id].xyz)\n",
    "local = np.array(local)\n",
    "print(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the georeferenced points\n",
    "georef = pd.read_csv(georef_points)\n",
    "georef.index = georef[\"Label\"]\n",
    "georef.drop(columns=[\"Label\"], inplace=True)\n",
    "georef.sort_values(\"Label\", inplace=True)\n",
    "if markers_to_use:\n",
    "    georef = georef[georef.index.isin(markers_to_use)]\n",
    "print(georef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate a Helmert transformation between the mean pcd and the ref.\n",
    "T = affine_matrix_from_points(\n",
    "    local.T, georef.to_numpy().T, shear=False, scale=True, usesvd=True\n",
    ")\n",
    "scale, _, angles, translation, _ = decompose_matrix(T)\n",
    "scale_percent = scale.mean() - 1\n",
    "angles_deg = np.rad2deg(angles)\n",
    "\n",
    "print(f\"Translation: {translation} m\")\n",
    "print(f\"Angles: {angles_deg} deg\")\n",
    "print(f\"Scale: {scale_percent:.6}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dense point cloud from roma to a ply file\n",
    "dense_rec = pycolmap.Reconstruction(dense_rec_path)\n",
    "dense_rec.export_PLY(dense_rec_path / \"dense.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and transform the point cloud\n",
    "pcd = o3d.io.read_point_cloud(str(dense_rec_path / \"dense_merged_clean.ply\"))\n",
    "georef_pcd = pcd.transform(T)\n",
    "o3d.io.write_point_cloud(str(dense_rec_path / \"dense_georef.ply\"), georef_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_rec_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-image-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
